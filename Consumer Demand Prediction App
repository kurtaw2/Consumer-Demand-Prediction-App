{"cells":[{"cell_type":"code","source":["import streamlit as st\n","import pandas as pd\n","import numpy as np\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import matplotlib.pyplot as plt\n","import xgboost as xgb\n","import os\n","\n","# --- PAGE CONFIGURATION ---\n","st.set_page_config(page_title=\"Textile Demand Predictor\", layout=\"wide\")\n","\n","st.title(\"ü§ñ AI Textile Demand Prediction System\")\n","st.markdown(\"\"\"\n","This application uses a **Random Forest** model to predict per-capita spending on clothing and footwear in the Philippines.\n","It integrates economic indicators (Inflation) and consumer sentiment (CES) to forecast demand.\n","\"\"\")\n","\n","# --- DATA LOADING FUNCTION ---\n","@st.cache_data\n","def load_and_process_data():\n","    # 1. Load Data (Robust Path Handling for Cloud)\n","    try:\n","        # Get the directory where app.py is located\n","        current_dir = os.path.dirname(os.path.abspath(__file__))\n","\n","        # Helper to get full path\n","        def get_path(filename):\n","            return os.path.join(current_dir, filename)\n","\n","        # Check if files exist\n","        required_files = ['HFCE_data.csv', 'Population_data.csv', 'Inflation_data.csv',\n","                          'CES_Tab_1.csv', 'CES_Tab_3.csv', 'CES_Tab_4.csv']\n","\n","        for f in required_files:\n","            if not os.path.exists(get_path(f)):\n","                st.error(f\"‚ùå Critical file not found: {f}\")\n","                st.info(\"Ensure all CSV files are uploaded to the same GitHub folder as this script.\")\n","                return None\n","\n","        hfce_df = pd.read_csv(get_path('HFCE_data.csv'), header=8, encoding='latin1')\n","        pop_df = pd.read_csv(get_path('Population_data.csv'), encoding='latin1')\n","        inflation_df = pd.read_csv(get_path('Inflation_data.csv'), encoding='latin1')\n","\n","    except Exception as e:\n","        st.error(f\"Error loading files: {e}\")\n","        return None\n","\n","    # --- 2. CLEANING HFCE ---\n","    id_col = hfce_df.columns[0]\n","    hfce_melt = hfce_df.melt(id_vars=id_col, var_name='Year', value_name='Value')\n","    hfce_target = hfce_melt[hfce_melt[id_col].astype(str).str.contains('Clothing and footwear', case=False, na=False)].copy()\n","    hfce_target = hfce_target.rename(columns={'Value': 'HFCE_Clothing_Footwear'})\n","\n","    # Year/Quarter Mapping\n","    year_map = {}\n","    for col_idx, col_value in enumerate(hfce_df.columns[1:]):\n","        if pd.notna(col_value):\n","            try:\n","                val_str = str(col_value).strip()\n","                if val_str.isdigit() and len(val_str) == 4:\n","                    current_year = int(val_str)\n","            except: pass\n","        year_map[col_idx + 1] = current_year if 'current_year' in locals() else None\n","\n","    year_labels = []\n","    quarter_labels = []\n","    quarter_names = ['Q1', 'Q2', 'Q3', 'Q4']\n","\n","    for i, row in hfce_target.iterrows():\n","        col_index = hfce_df.columns.get_loc(row['Year'])\n","        year = year_map.get(col_index)\n","        quarter = quarter_names[(col_index - 1) % 4]\n","        year_labels.append(year)\n","        quarter_labels.append(quarter)\n","\n","    hfce_target['Year'] = year_labels\n","    hfce_target['Quarter'] = quarter_labels\n","    hfce_target.dropna(subset=['Year', 'Quarter'], inplace=True)\n","    hfce_target['Year'] = hfce_target['Year'].astype(int)\n","\n","    # Numeric Conversion & Scaling\n","    hfce_target['HFCE_Clothing_Footwear'] = pd.to_numeric(hfce_target['HFCE_Clothing_Footwear'].astype(str).str.replace(',', ''), errors='coerce')\n","    hfce_target.dropna(subset=['HFCE_Clothing_Footwear'], inplace=True)\n","    hfce_target['HFCE_Clothing_Footwear'] = hfce_target['HFCE_Clothing_Footwear'] * 1_000_000 # Scale to Pesos\n","\n","    # --- 3. CLEANING POPULATION ---\n","    pop_df = pop_df.rename(columns={'Annual Population Source': 'Annual_Population_Source',\n","                                    'Interpolated Quarterly Estimate': 'Quarterly_Population'})\n","    pop_df['Quarterly_Population'] = pd.to_numeric(pop_df['Quarterly_Population'].astype(str).str.replace(',', ''), errors='coerce')\n","    pop_df.dropna(subset=['Quarterly_Population'], inplace=True)\n","    pop_df['Year'].ffill(inplace=True)\n","    pop_df['Quarter_Index'] = pop_df.groupby('Year').cumcount()\n","    pop_df['Quarter'] = pop_df['Quarter_Index'].apply(lambda x: 'Q' + str(x % 4 + 1))\n","    pop_df = pop_df[['Year', 'Quarter', 'Quarterly_Population']]\n","    pop_df['Year'] = pop_df['Year'].astype(int)\n","\n","    # --- 4. CES EXTRACTION HELPER ---\n","    def extract_ces(file_name, search_term, col_name):\n","        try:\n","            # Load with robust path\n","            full_path = os.path.join(current_dir, file_name)\n","            df_raw = pd.read_csv(full_path, header=None, encoding='latin1')\n","            quarter_row_idx = None\n","            for idx, row in df_raw.iterrows():\n","                row_text = \" \".join(row.astype(str).values)\n","                if 'Q1' in row_text and 'Q2' in row_text:\n","                    quarter_row_idx = idx\n","                    break\n","\n","            if quarter_row_idx is None: return pd.DataFrame()\n","\n","            year_row_idx = quarter_row_idx - 1\n","            indicator_row_idx = None\n","\n","            if search_term == 'ROW_0_fallback':\n","                 for idx in range(quarter_row_idx + 1, min(quarter_row_idx + 20, len(df_raw))):\n","                     try:\n","                         float(str(df_raw.iloc[idx, 2]).replace(',', ''))\n","                         indicator_row_idx = idx\n","                         break\n","                     except: continue\n","\n","            if indicator_row_idx is None: return pd.DataFrame()\n","\n","            quarter_row = df_raw.iloc[quarter_row_idx]\n","            year_row = df_raw.iloc[year_row_idx]\n","            data_row = df_raw.iloc[indicator_row_idx]\n","\n","            dates, values = [], []\n","            current_year = None\n","\n","            for col_idx in range(1, len(df_raw.columns)):\n","                val_year = year_row[col_idx]\n","                if pd.notna(val_year):\n","                    try:\n","                        year_str = str(val_year).strip().replace(',', '').replace('.0', '')\n","                        if year_str.isdigit() and len(year_str) == 4:\n","                            current_year = int(year_str)\n","                    except: pass\n","\n","                val_qtr = quarter_row[col_idx]\n","                val_data = data_row[col_idx]\n","\n","                if pd.notna(val_qtr) and pd.notna(val_data) and current_year is not None:\n","                    qtr_str = str(val_qtr).strip()\n","                    if qtr_str in ['Q1', 'Q2', 'Q3', 'Q4']:\n","                        dates.append((current_year, qtr_str))\n","                        values.append(val_data)\n","\n","            df_clean = pd.DataFrame(dates, columns=['Year', 'Quarter'])\n","            df_clean[col_name] = pd.to_numeric(pd.Series(values).astype(str).str.replace(',', ''), errors='coerce')\n","            return df_clean.dropna()\n","        except: return pd.DataFrame()\n","\n","    # Load CES Tabs\n","    df_ccis = extract_ces('CES_Tab_1.csv', 'ROW_0_fallback', 'CCIS_Overall')\n","    df_fin = extract_ces('CES_Tab_3.csv', 'ROW_0_fallback', 'CES_FinCondition')\n","    df_inc = extract_ces('CES_Tab_4.csv', 'ROW_0_fallback', 'CES_Income')\n","\n","    # Clean Inflation\n","    inflation_df.columns = ['Year', 'Quarter_Int', 'Inflation_Rate']\n","    inflation_df['Quarter'] = inflation_df['Quarter_Int'].apply(lambda x: f'Q{int(x)}')\n","    inflation_df['Year'] = pd.to_numeric(inflation_df['Year'], errors='coerce')\n","    inflation_df = inflation_df[['Year', 'Quarter', 'Inflation_Rate']].dropna()\n","\n","    # --- 5. MERGE ALL ---\n","    data = pd.merge(hfce_target, pop_df, on=['Year', 'Quarter'], how='inner')\n","\n","    # Merge Features\n","    for df in [df_ccis, df_fin, df_inc]:\n","        if not df.empty:\n","            data = pd.merge(data, df, on=['Year', 'Quarter'], how='left')\n","\n","    data = pd.merge(data, inflation_df, on=['Year', 'Quarter'], how='left')\n","\n","    # Filter & Impute\n","    data = data[data['Year'] >= 2007] # CES Start\n","    data = data.sort_values(by=['Year', 'Quarter'])\n","    data.fillna(method='ffill', inplace=True)\n","    data.fillna(method='bfill', inplace=True)\n","\n","    # Calculate Target\n","    data['HFCE_Per_Capita'] = data['HFCE_Clothing_Footwear'] / data['Quarterly_Population']\n","\n","    # --- FEATURE ENGINEERING ---\n","    data['HFCE_Lag1'] = data['HFCE_Per_Capita'].shift(1)\n","    data['HFCE_Lag2'] = data['HFCE_Per_Capita'].shift(2)\n","    data['HFCE_Lag4'] = data['HFCE_Per_Capita'].shift(4)\n","    # FIX: Shift before rolling to prevent leakage\n","    data['RollingMean_4'] = data['HFCE_Per_Capita'].shift(1).rolling(window=4).mean()\n","\n","    data.dropna(inplace=True)\n","\n","    # One-Hot Encoding\n","    data = pd.get_dummies(data, columns=['Quarter'], drop_first=False) # Keep all quarters for display\n","\n","    return data\n","\n","# --- MAIN APP LOGIC ---\n","\n","df = load_and_process_data()\n","\n","if df is not None:\n","    # Sidebar Controls\n","    st.sidebar.header(\"üõ†Ô∏è Model Controls\")\n","    test_size = st.sidebar.slider(\"Test Set Size (%)\", 10, 50, 30) / 100\n","    n_estimators = st.sidebar.slider(\"Number of Trees\", 50, 500, 200)\n","\n","    # Split Data\n","    # Identify feature columns (exclude non-numeric or target)\n","    target = 'HFCE_Per_Capita'\n","    features = [c for c in df.columns if c not in [target, 'HFCE_Clothing_Footwear', 'Quarterly_Population']]\n","\n","    # Separate Train/Test chronologically\n","    split_idx = int(len(df) * (1 - test_size))\n","    X = df[features]\n","    y = df[target]\n","\n","    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n","    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n","\n","    # Train Model (Using best params found earlier)\n","    rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=10,\n","                               min_samples_split=5, min_samples_leaf=2, random_state=42)\n","    rf.fit(X_train, y_train)\n","\n","    # Predictions\n","    y_pred = rf.predict(X_test)\n","\n","    # --- METRICS DISPLAY ---\n","    col1, col2, col3 = st.columns(3)\n","    col1.metric(\"R¬≤ Score (Accuracy)\", f\"{r2_score(y_test, y_pred):.2f}\")\n","    col2.metric(\"MAE (Avg Error)\", f\"‚Ç±{mean_absolute_error(y_test, y_pred):.2f}\")\n","    col3.metric(\"RMSE\", f\"‚Ç±{np.sqrt(mean_squared_error(y_test, y_pred)):.2f}\")\n","\n","    # --- VISUALIZATIONS ---\n","    st.subheader(\"üìà Consumption Forecast vs. Actual\")\n","\n","    # Create comparison dataframe for chart\n","    chart_data = pd.DataFrame({\n","        'Actual Spending': y_test.values,\n","        'Predicted Spending': y_pred\n","    }, index=df.iloc[split_idx:]['Year'].astype(str)) # Use Year as index for chart\n","\n","    st.line_chart(chart_data)\n","\n","    # Feature Importance\n","    st.subheader(\"üîç What Drives Demand?\")\n","    importance = pd.DataFrame({\n","        'Feature': features,\n","        'Importance': rf.feature_importances_\n","    }).sort_values(by='Importance', ascending=False)\n","\n","    st.bar_chart(importance.set_index('Feature'))\n","\n","    # --- SIMULATOR ---\n","    st.markdown(\"---\")\n","    st.subheader(\"üîÆ Demand Simulator\")\n","    st.write(\"Adjust economic factors to see how they impact predicted clothing spending.\")\n","\n","    c1, c2, c3 = st.columns(3)\n","    user_inflation = c1.number_input(\"Inflation Rate (%)\", value=5.0)\n","    user_sentiment = c2.number_input(\"Consumer Confidence Index\", value=-10.0)\n","    user_lag = c3.number_input(\"Last Quarter's Spending (‚Ç±)\", value=1500.0)\n","\n","    # Create a dummy row for prediction (Simplified)\n","    # Ideally, we would need to reconstruct all lags, but for a simple demo\n","    # we take the last known state and update the user inputs.\n","    input_data = X_test.iloc[-1:].copy()\n","\n","    # Map user inputs to features if they exist\n","    if 'Inflation_Rate' in input_data.index: input_data['Inflation_Rate'] = user_inflation\n","    if 'CCIS_Overall' in input_data.index: input_data['CCIS_Overall'] = user_sentiment\n","    if 'HFCE_Lag1' in input_data.index: input_data['HFCE_Lag1'] = user_lag\n","\n","    sim_pred = rf.predict([input_data])[0]\n","    st.success(f\"Estimated Spending: **‚Ç±{sim_pred:,.2f}** per person\")\n","\n","else:\n","    st.warning(\"Data could not be loaded. Please check your CSV files.\")"],"outputs":[{"output_type":"stream","name":"stderr","text":["2025-12-01 16:05:50.071 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-12-01 16:05:50.074 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-12-01 16:05:50.476 \n","  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n","  command:\n","\n","    streamlit run /usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n","2025-12-01 16:05:50.479 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-12-01 16:05:50.482 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-12-01 16:05:50.486 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-12-01 16:05:50.488 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-12-01 16:05:50.492 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-12-01 16:05:50.501 No runtime found, using MemoryCacheStorageManager\n","2025-12-01 16:05:50.518 No runtime found, using MemoryCacheStorageManager\n","2025-12-01 16:05:50.519 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-12-01 16:05:50.520 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-12-01 16:05:50.520 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-12-01 16:05:50.521 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-12-01 16:05:50.523 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-12-01 16:05:50.524 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-12-01 16:05:50.526 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-12-01 16:05:50.526 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-12-01 16:05:50.527 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-12-01 16:05:50.528 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-12-01 16:05:50.530 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-12-01 16:05:50.532 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n","2025-12-01 16:05:50.533 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"]}],"execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_qNdXwd4pitR","executionInfo":{"status":"ok","timestamp":1764605151883,"user_tz":-480,"elapsed":15030,"user":{"displayName":"Venz Arthur Torregosa","userId":"08092280453522098212"}},"outputId":"2a8c3980-6c34-453c-d530-3a9e5fe7c932"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rlhPm-d6pkJx","executionInfo":{"status":"ok","timestamp":1764604968504,"user_tz":-480,"elapsed":23947,"user":{"displayName":"Venz Arthur Torregosa","userId":"08092280453522098212"}},"outputId":"5018c613-5515-47b4-e244-f290b30a66b5"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}