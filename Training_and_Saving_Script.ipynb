{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kurtaw2/Consumer-Demand-Prediction-App/blob/main/Training_and_Saving_Script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import os\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "# Removed: from google.colab import drive\n",
        "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "# --- Configuration for Data Loading & Model Saving ---\n",
        "# Data files are now assumed to be in the local working directory (the repository root)\n",
        "DATA_FOLDER = '.'\n",
        "HFCE_FILE_NAME = 'HFCE_data.csv'\n",
        "POP_FILE_NAME = 'Population_data.csv'\n",
        "INFLATION_FILE_NAME = 'Inflation_data.csv'\n",
        "\n",
        "# Output Configuration: Saved to a relative folder within the repository\n",
        "MODEL_OUTPUT_FOLDER = 'HFCE_Predictor_Artifacts'\n",
        "MODEL_DIR = MODEL_OUTPUT_FOLDER # Relative path\n",
        "PREDICTOR_FILENAME = 'hfce_predictor.joblib'\n",
        "FEATURES_FILENAME = 'hfce_features.joblib'\n",
        "DEFAULTS_FILENAME = 'hfce_defaults.joblib'\n",
        "MODEL_EXPORT_PATH = os.path.join(MODEL_DIR, PREDICTOR_FILENAME)\n",
        "FEATURES_EXPORT_PATH = os.path.join(MODEL_DIR, FEATURES_FILENAME)\n",
        "DEFAULTS_EXPORT_PATH = os.path.join(MODEL_DIR, DEFAULTS_FILENAME)\n",
        "\n",
        "# File paths using the local DATA_FOLDER\n",
        "hfce_file = os.path.join(DATA_FOLDER, HFCE_FILE_NAME)\n",
        "pop_file = os.path.join(DATA_FOLDER, POP_FILE_NAME)\n",
        "inflation_file = os.path.join(DATA_FOLDER, INFLATION_FILE_NAME)\n",
        "\n",
        "def get_ces_file_path(tab_num):\n",
        "    return os.path.join(DATA_FOLDER, f'CES_Tab_{tab_num}.csv')\n",
        "\n",
        "# --- Helper Function (Data Extraction - Unchanged Logic) ---\n",
        "def extract_ces_indicator(file_path, indicator_search_term, new_column_name):\n",
        "    \"\"\"\n",
        "    Robustly loads a CES file by searching for the 'Year'/'Quarter' structure\n",
        "    and the specific indicator row by name/keyword.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"Warning: File not found at {file_path}\")\n",
        "            return pd.DataFrame()\n",
        "        df_raw = pd.read_csv(file_path, header=None, encoding='latin1')\n",
        "\n",
        "        # 1. FIND THE QUARTER ROW (contains 'Q1', 'Q2', 'Q3', 'Q4')\n",
        "        quarter_row_idx = None\n",
        "        for idx, row in df_raw.iterrows():\n",
        "            row_str = row.astype(str).values\n",
        "            row_text = \" \".join(row_str)\n",
        "            if 'Q1' in row_text and 'Q2' in row_text and 'Q3' in row_text:\n",
        "                quarter_row_idx = idx\n",
        "                break\n",
        "\n",
        "        if quarter_row_idx is None:\n",
        "            print(f\"WARNING: Could not find Quarter labels (Q1, Q2...) in {file_path}\")\n",
        "            return pd.DataFrame()\n",
        "        year_row_idx = quarter_row_idx - 1\n",
        "\n",
        "        # 2. FIND THE INDICATOR DATA ROW\n",
        "        indicator_row_idx = None\n",
        "        if indicator_search_term == 'ROW_0_fallback':\n",
        "             for idx in range(quarter_row_idx + 1, min(quarter_row_idx + 20, len(df_raw))):\n",
        "                 try:\n",
        "                     val_str = str(df_raw.iloc[idx, 2]).replace(',', '').strip()\n",
        "                     if val_str and val_str.lower() != 'nan':\n",
        "                         float(val_str)\n",
        "                         indicator_row_idx = idx\n",
        "                         break\n",
        "                 except:\n",
        "                     continue\n",
        "        else:\n",
        "            for idx, row in df_raw.iterrows():\n",
        "                if idx <= quarter_row_idx: continue\n",
        "                first_cell = str(row[0])\n",
        "                if indicator_search_term.lower() in first_cell.lower():\n",
        "                    indicator_row_idx = idx\n",
        "                    break\n",
        "\n",
        "        if indicator_row_idx is None:\n",
        "            print(f\"WARNING: Could not find valid data row for '{indicator_search_term}' in {file_path}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # 3. EXTRACT DATA\n",
        "        quarter_row = df_raw.iloc[quarter_row_idx]\n",
        "        year_row = df_raw.iloc[year_row_idx]\n",
        "        data_row = df_raw.iloc[indicator_row_idx]\n",
        "\n",
        "        dates = []\n",
        "        values = []\n",
        "        current_year = None\n",
        "\n",
        "        for col_idx in range(1, len(df_raw.columns)):\n",
        "            val_year = year_row[col_idx]\n",
        "            if pd.notna(val_year):\n",
        "                try:\n",
        "                    year_str = str(val_year).strip().replace(',', '')\n",
        "                    if year_str.replace('.0', '').isdigit() and len(year_str.replace('.0', '')) == 4:\n",
        "                        current_year = int(year_str.replace('.0', ''))\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "            val_qtr = quarter_row[col_idx]\n",
        "            val_data = data_row[col_idx]\n",
        "\n",
        "            if pd.notna(val_qtr) and pd.notna(val_data) and current_year is not None:\n",
        "                qtr_str = str(val_qtr).strip()\n",
        "                if qtr_str in ['Q1', 'Q2', 'Q3', 'Q4']:\n",
        "                    dates.append((current_year, qtr_str))\n",
        "                    values.append(val_data)\n",
        "\n",
        "        df_cleaned = pd.DataFrame(dates, columns=['Year', 'Quarter'])\n",
        "        df_cleaned[new_column_name] = values\n",
        "\n",
        "        df_cleaned[new_column_name] = df_cleaned[new_column_name].astype(str).str.replace(',', '')\n",
        "        df_cleaned[new_column_name] = pd.to_numeric(df_cleaned[new_column_name], errors='coerce')\n",
        "\n",
        "        df_cleaned.dropna(inplace=True)\n",
        "        return df_cleaned\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing {file_path}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# --- Main Training and Saving Function ---\n",
        "\n",
        "def train_and_save_model():\n",
        "    # --- 1. Load Primary Data ---\n",
        "    try:\n",
        "        print(\"--- Loading primary data ---\")\n",
        "        hfce_df = pd.read_csv(hfce_file, header=8, encoding='latin1')\n",
        "        pop_df = pd.read_csv(pop_file, encoding='latin1')\n",
        "        df_inflation_raw = pd.read_csv(inflation_file, encoding='latin1')\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"FATAL ERROR: A required file was not found: {e}\")\n",
        "        print(f\"Please ensure all CSV files are in the folder: {DATA_FOLDER}\")\n",
        "        return\n",
        "\n",
        "    # --- 2. Clean HFCE Data (same logic as user provided) ---\n",
        "    print(\"\\n--- Cleaning HFCE Data ---\")\n",
        "    id_col = hfce_df.columns[0]\n",
        "    hfce_melt = hfce_df.melt(id_vars=id_col, var_name='Year', value_name='Value')\n",
        "    hfce_target = hfce_melt[hfce_melt[id_col].astype(str).str.contains('Clothing and footwear', case=False, na=False)].copy()\n",
        "    hfce_target = hfce_target.rename(columns={'Value': 'HFCE_Clothing_Footwear'})\n",
        "\n",
        "    year_map = {}\n",
        "    current_year = None\n",
        "    for col_idx, col_value in enumerate(hfce_df.columns[1:]):\n",
        "        if pd.notna(col_value):\n",
        "            try:\n",
        "                val_str = str(col_value).strip()\n",
        "                if val_str.isdigit() and len(val_str) == 4:\n",
        "                    current_year = int(val_str)\n",
        "            except: pass\n",
        "        year_map[col_idx + 1] = current_year\n",
        "\n",
        "    year_labels = []\n",
        "    quarter_labels = []\n",
        "    quarter_names = ['Q1', 'Q2', 'Q3', 'Q4']\n",
        "    for i, row in hfce_target.iterrows():\n",
        "        col_index = hfce_df.columns.get_loc(row['Year'])\n",
        "        year = year_map.get(col_index)\n",
        "        quarter = quarter_names[(col_index - 1) % 4]\n",
        "        year_labels.append(year)\n",
        "        quarter_labels.append(quarter)\n",
        "\n",
        "    hfce_target['Year'] = year_labels\n",
        "    hfce_target['Quarter'] = quarter_labels\n",
        "    hfce_target.dropna(subset=['Year', 'Quarter'], inplace=True)\n",
        "    hfce_target['Year'] = hfce_target['Year'].astype(int)\n",
        "\n",
        "    hfce_target['HFCE_Clothing_Footwear'] = pd.to_numeric(hfce_target['HFCE_Clothing_Footwear'].astype(str).str.replace(',', ''), errors='coerce')\n",
        "    hfce_target.dropna(subset=['HFCE_Clothing_Footwear'], inplace=True)\n",
        "    hfce_target['HFCE_Clothing_Footwear'] = hfce_target['HFCE_Clothing_Footwear'] * 1_000_000\n",
        "\n",
        "    # --- 3. Clean Population Data ---\n",
        "    pop_df = pop_df.rename(columns={'Annual Population Source': 'Annual_Population_Source',\n",
        "                                     'Interpolated Quarterly Estimate': 'Quarterly_Population'})\n",
        "    pop_df['Quarterly_Population'] = pd.to_numeric(pop_df['Quarterly_Population'].astype(str).str.replace(',', ''), errors='coerce')\n",
        "    pop_df.dropna(subset=['Quarterly_Population'], inplace=True)\n",
        "    pop_df['Year'].ffill(inplace=True)\n",
        "    pop_df['Quarter_Index'] = pop_df.groupby('Year').cumcount()\n",
        "    pop_df['Quarter'] = pop_df['Quarter_Index'].apply(lambda x: 'Q' + str(x % 4 + 1))\n",
        "    pop_df = pop_df[['Year', 'Quarter', 'Quarterly_Population']]\n",
        "    pop_df['Year'] = pop_df['Year'].astype(int)\n",
        "\n",
        "    # --- 4. Load CES Data & Inflation ---\n",
        "    print(\"\\n--- Extracting CES Features ---\")\n",
        "    df_ccis = extract_ces_indicator(get_ces_file_path(1), 'ROW_0_fallback', 'CCIS_Overall')\n",
        "    df_fin_cond = extract_ces_indicator(get_ces_file_path(3), 'ROW_0_fallback', 'CES_FinCondition')\n",
        "    df_income = extract_ces_indicator(get_ces_file_path(4), 'ROW_0_fallback', 'CES_Income')\n",
        "\n",
        "    df_inflation_raw.columns = ['Year', 'Quarter_Int', 'Inflation_Annual_Static_Rate']\n",
        "    df_inflation_raw['Quarter'] = df_inflation_raw['Quarter_Int'].apply(lambda x: f'Q{int(x)}')\n",
        "    df_inflation_raw['Year'] = pd.to_numeric(df_inflation_raw['Year'], errors='coerce').astype('Int64')\n",
        "    df_inflation = df_inflation_raw[['Year', 'Quarter', 'Inflation_Annual_Static_Rate']].copy()\n",
        "    df_inflation.dropna(inplace=True)\n",
        "\n",
        "    # --- 5. Merge, Filter, and Feature Engineer ---\n",
        "    data = pd.merge(hfce_target, pop_df, on=['Year', 'Quarter'], how='inner')\n",
        "\n",
        "    ces_dfs = [\n",
        "        (df_ccis, 'CCIS (Tab 1)'),\n",
        "        (df_fin_cond, 'Financial Condition (Tab 3)'),\n",
        "        (df_income, 'Income Outlook (Tab 4)')\n",
        "    ]\n",
        "    for df_feature, name in ces_dfs:\n",
        "        if not df_feature.empty:\n",
        "            data = pd.merge(data, df_feature, on=['Year', 'Quarter'], how='left')\n",
        "        else:\n",
        "            print(f\"MERGE FAIL: {name} DataFrame is empty.\")\n",
        "    data = pd.merge(data, df_inflation, on=['Year', 'Quarter'], how='left')\n",
        "\n",
        "    data = data[data['Year'] >= 2007]\n",
        "\n",
        "    data.sort_values(by=['Year', 'Quarter'], inplace=True)\n",
        "    data.fillna(method='ffill', inplace=True)\n",
        "    data.fillna(method='bfill', inplace=True)\n",
        "    data.fillna(0, inplace=True)\n",
        "\n",
        "    data = data[data['Quarterly_Population'] > 0]\n",
        "    data['HFCE_Per_Capita'] = data['HFCE_Clothing_Footwear'] / data['Quarterly_Population']\n",
        "\n",
        "    # --- CAPTURE LAST KNOWN DATA BEFORE FEATURE ENGINEERING (for app defaults) ---\n",
        "    # We capture the last row *before* feature engineering creates NaNs\n",
        "    last_known_row_pre_fe = data.iloc[-1].copy()\n",
        "\n",
        "    # Feature Engineering\n",
        "    data['HFCE_Lag1'] = data['HFCE_Per_Capita'].shift(1)\n",
        "    data['HFCE_Lag2'] = data['HFCE_Per_Capita'].shift(2)\n",
        "    data['HFCE_Lag4'] = data['HFCE_Per_Capita'].shift(4)\n",
        "    data['HFCE_RollingMean_2'] = data['HFCE_Per_Capita'].shift(1).rolling(window=2).mean()\n",
        "    data['HFCE_RollingMean_4'] = data['HFCE_Per_Capita'].shift(1).rolling(window=4).mean()\n",
        "    data['Inflation_Growth'] = data['Inflation_Annual_Static_Rate'].pct_change()\n",
        "    data['CCIS_Growth'] = data['CCIS_Overall'].pct_change()\n",
        "    data.replace([np.inf, -np.inf], 0, inplace=True)\n",
        "\n",
        "    # Drop NaNs created by shifting/rolling\n",
        "    data.dropna(subset=['HFCE_Lag4', 'HFCE_RollingMean_4'], inplace=True)\n",
        "    data.drop(columns=['HFCE_Clothing_Footwear', 'Quarterly_Population'], inplace=True)\n",
        "\n",
        "    # --- Final Pre-processing of Last Row for Accurate Defaults ---\n",
        "    # Recalculate lags and growth rates for the last *valid* row of data for defaults\n",
        "    # Find the row in the fully processed 'data' just before the last row (this is the true source of prediction defaults)\n",
        "    last_known_row_post_fe = data.iloc[-1]\n",
        "\n",
        "    # --- 6. Final Data Preparation ---\n",
        "    data = pd.get_dummies(data, columns=['Quarter'], drop_first=True)\n",
        "    if 'Unnamed: 0' in data.columns:\n",
        "        data.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "\n",
        "    y = data['HFCE_Per_Capita']\n",
        "    X = data.drop(columns=['HFCE_Per_Capita'])\n",
        "\n",
        "    for col in X.columns:\n",
        "        X[col] = pd.to_numeric(X[col], errors='coerce')\n",
        "    X.dropna(axis=1, how='all', inplace=True)\n",
        "    X.fillna(0, inplace=True)\n",
        "    y = pd.to_numeric(y, errors='coerce')\n",
        "    valid_indices = y.dropna().index\n",
        "    X = X.loc[valid_indices]\n",
        "    y = y.loc[valid_indices]\n",
        "\n",
        "    if len(X) == 0:\n",
        "        print(\"Final dataset is empty. Cannot train model.\")\n",
        "        return\n",
        "\n",
        "    # --- 7. Model Training and Selection ---\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "    xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
        "    rf_model = RandomForestRegressor(n_estimators=200, max_depth=10, min_samples_split=5,\n",
        "                                     min_samples_leaf=2, random_state=42)\n",
        "\n",
        "    xgb_cv_scores = cross_val_score(xgb_model, X, y, cv=tscv, scoring='r2')\n",
        "    rf_cv_scores = cross_val_score(rf_model, X, y, cv=tscv, scoring='r2')\n",
        "\n",
        "    if xgb_cv_scores.mean() > rf_cv_scores.mean():\n",
        "        print(f\"\\n>>> Selected XGBoost (R²: {xgb_cv_scores.mean():.4f})\")\n",
        "        best_model = xgb_model\n",
        "    else:\n",
        "        print(f\"\\n>>> Selected Random Forest (R²: {rf_cv_scores.mean():.4f})\")\n",
        "        best_model = rf_model\n",
        "\n",
        "    # Train the FINAL model on the ENTIRE clean dataset (X, y)\n",
        "    print(\"Training final model on entire dataset for production export...\")\n",
        "    best_model.fit(X, y)\n",
        "\n",
        "    # --- 8. Model Saving and Defaults Export ---\n",
        "    try:\n",
        "        # Define the dictionary of dynamic defaults for the UI\n",
        "        dynamic_defaults = {\n",
        "            # The most recent known historical data point:\n",
        "            'Year': int(last_known_row_post_fe['Year']),\n",
        "            'HFCE_Per_Capita': float(y.iloc[-1]), # The actual last predicted target value from the training data\n",
        "            'HFCE_Lag1': float(last_known_row_post_fe['HFCE_Per_Capita']), # Last quarter's final consumption\n",
        "            'HFCE_Lag2': float(last_known_row_post_fe['HFCE_Lag1']),\n",
        "            'HFCE_Lag4': float(last_known_row_post_fe['HFCE_Lag4']),\n",
        "            'CCIS_Overall': float(last_known_row_post_fe['CCIS_Overall']),\n",
        "            'CES_FinCondition': float(last_known_row_post_fe['CES_FinCondition']),\n",
        "            'CES_Income': float(last_known_row_post_fe['CES_Income']),\n",
        "            'Inflation_Annual_Static_Rate': float(last_known_row_post_fe['Inflation_Annual_Static_Rate']),\n",
        "        }\n",
        "\n",
        "        # Create the models directory in the local repo if it doesn't exist\n",
        "        os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "        # Save the trained model\n",
        "        joblib.dump(best_model, MODEL_EXPORT_PATH)\n",
        "\n",
        "        # Save the feature column list (CRITICAL for prediction)\n",
        "        joblib.dump(X.columns.tolist(), FEATURES_EXPORT_PATH)\n",
        "\n",
        "        # Save the dynamic defaults\n",
        "        joblib.dump(dynamic_defaults, DEFAULTS_EXPORT_PATH)\n",
        "\n",
        "        print(\"\\n\" + \"-\" * 60)\n",
        "        print(f\"✅ MODEL EXPORT SUCCESSFUL (Local Repo Paths)\")\n",
        "        print(f\"Trained Model saved to: {MODEL_EXPORT_PATH}\")\n",
        "        print(f\"Feature List saved to: {FEATURES_EXPORT_PATH}\")\n",
        "        print(f\"Dynamic Defaults saved to: {DEFAULTS_EXPORT_PATH}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nFATAL ERROR during model serialization/export: {e}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # You should run this script once in your local repository environment.\n",
        "    # The output folder 'HFCE_Predictor_Artifacts' will be created locally.\n",
        "    train_and_save_model()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "MrssDAejd6ym"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}